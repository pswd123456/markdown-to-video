# src/components/critic.py
import base64
import json
import asyncio
from pathlib import Path

from src.core.models import CritiqueFeedback, SceneSpec
from src.core.config import settings
from src.llm.client import LLMClient
# å¼•å…¥æ–°çš„æ„å»ºå‡½æ•°
from src.llm.prompts import build_critic_system_prompt, build_critic_user_prompt 

class VisionCritic:
    def __init__(self):
        # è¿™é‡Œçš„ LLMClient å·²ç»æ˜¯å¼‚æ­¥ç‰ˆæœ¬äº†
        self.llm_client = LLMClient()
        self.model = settings.CRITIC_MODEL
        
        # === æ–°å¢ï¼šåŠ è½½ä¸Šä¸‹æ–‡èµ„æº ===
        # å¤ç”¨ lib ç›®å½•ä¸‹çš„èµ„æºï¼Œä¿è¯ Coder å’Œ Critic çœ‹åˆ°çš„æ˜¯åŒä¸€å¥—è§„åˆ™
        self.api_stubs = self._load_file(settings.LIB_DIR / "api_stubs.txt")
        self.examples = self._load_file(settings.LIB_DIR / "examples.txt")

    def _load_file(self, path: Path) -> str:
        """è¾…åŠ©æ–¹æ³•ï¼šè¯»å–æ–‡ä»¶"""
        try:
            return path.read_text(encoding="utf-8")
        except FileNotFoundError:
            return ""

    def _encode_image(self, image_path: str) -> str:
        """å°†å›¾ç‰‡è½¬æ¢ä¸º Base64 ç¼–ç """
        path = Path(image_path)
        if not path.exists():
            # è¿™é‡Œå¯ä»¥åšä¸€ä¸ªå…œåº•ï¼Œå¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œå°±ä¸è¦å»å®¡æŸ¥äº†
            return ""
            
        with open(path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    async def review_layout(self, image_path: str, scene: SceneSpec) -> CritiqueFeedback:
        """
        [Async] è§†è§‰å®¡æŸ¥
        """
        print(f"ğŸ‘€ [Critic] Reviewing image: {image_path}")
        
        # å›¾ç‰‡ç¼–ç æ˜¯ CPU å¯†é›†å‹æ“ä½œï¼Œä½†å¯¹äºå•å¼ å›¾ç‰‡é€šå¸¸å¾ˆå¿«ã€‚
        # å¦‚æœå›¾ç‰‡å¾ˆå¤§ï¼Œå¯ä»¥è€ƒè™‘ await asyncio.to_thread(self._encode_image, image_path)
        base64_image = self._encode_image(image_path)
        
        if not base64_image:
            print("   âš ï¸ Image not found, skipping critique.")
            return CritiqueFeedback(passed=True, score=10, suggestion=None)
        
        # === ä¿®æ”¹ç‚¹ï¼šæ„å»ºåŠ¨æ€ System Prompt ===
        system_prompt = build_critic_system_prompt(self.api_stubs, self.examples)
        
        user_content = build_critic_user_prompt(scene)

        try:
            # å…³é”®ä¿®å¤: è¿™é‡Œä½¿ç”¨ await è°ƒç”¨å¼‚æ­¥çš„ LLMClient
            # æ³¨æ„ï¼šLLMClient.client æ˜¯ AsyncOpenAI å®ä¾‹
            response = await self.llm_client.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": user_content},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.1, # é™ä½æ¸©åº¦ï¼Œè®©å®ƒä¸¥æ ¼éµå¾ª API çº¦æŸ
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            # ç®€å•çš„æ¸…æ´—é€»è¾‘
            content = content.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(content)
            
            return CritiqueFeedback(
                passed=data.get("passed", False),
                score=data.get("score", 0),
                suggestion=data.get("suggestion")
            )

        except Exception as e:
            print(f"âš ï¸ [Critic] Validation failed due to API error: {e}")
            # å‡ºé”™æ—¶é»˜è®¤é€šè¿‡ï¼Œé¿å…å¡æ­»æµæ°´çº¿ï¼Œä½†åˆ†æ•°ç»™ä½ä¸€ç‚¹
            return CritiqueFeedback(passed=True, score=5, suggestion=None)