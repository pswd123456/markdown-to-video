import base64
import json
from pathlib import Path
from typing import Dict, Any

from src.core.models import CritiqueFeedback, SceneSpec
from src.core.config import settings
from src.llm.client import LLMClient

class VisionCritic:
    def __init__(self):
        # å¤ç”¨ LLM Clientï¼Œä½†æ³¨æ„æˆ‘ä»¬å°†åœ¨è°ƒç”¨æ—¶æŒ‡å®š Vision æ¨¡å‹
        self.llm_client = LLMClient()
        self.model = settings.CRITIC_MODEL  # e.g., "qwen-vl-max"

    def _encode_image(self, image_path: str) -> str:
        """å°†å›¾ç‰‡è½¬æ¢ä¸º Base64 ç¼–ç """
        path = Path(image_path)
        if not path.exists():
            raise FileNotFoundError(f"Image not found: {image_path}")
            
        with open(path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def review_layout(self, image_path: str, scene: SceneSpec) -> CritiqueFeedback:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šçœ‹å›¾æ‰¾èŒ¬
        """
        print(f"ğŸ‘€ [Critic] Reviewing image: {image_path}")
        
        base64_image = self._encode_image(image_path)
        
        # 1. æ„å»º Prompt (å¼ºåˆ¶ JSON è¾“å‡º)
        system_prompt = """
You are a strict Visual QA Specialist for Manim animations.
Your job is to inspect the last frame of a video and check for layout issues.

CHECKLIST:
1. Overlaps: Are any text or objects overlapping unintentionally?
2. Cut-offs: Is any content partially outside the frame (16:9 aspect ratio)?
3. Legibility: Is the text too small or low contrast?
4. Completeness: Does the image match the user's description?

OUTPUT FORMAT:
Return a JSON object ONLY (no markdown formatting):
{
    "passed": boolean,
    "score": int (0-10),
    "suggestion": "string (If failed, provide a specific Python fix suggestion using 'next_to', 'scale', or 'shift'. If passed, return null)"
}
"""
        
        user_content = f"""
User Description: "{scene.description}"
Main Elements: {', '.join(scene.elements)}

Analyze the attached image based on the checklist.
"""

        # 2. è°ƒç”¨ Vision Model (OpenAI å…¼å®¹æ ¼å¼)
        try:
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨æ„é€ è¯·æ±‚ï¼Œå› ä¸º client.py å°è£…å¯èƒ½æ¯”è¾ƒç®€å•
            # å¦‚æœä½ çš„ LLMClient ä¸æ”¯æŒ image_urlï¼Œè¿™é‡Œéœ€è¦ç›´æ¥è°ƒç”¨ client.chat.completions
            response = self.llm_client.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": user_content},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.1, # è¯„ä»·éœ€è¦å®¢è§‚
                response_format={"type": "json_object"} # å¼ºåˆ¶ JSON (å¦‚æœæ¨¡å‹æ”¯æŒ)
            )
            
            content = response.choices[0].message.content
            # æ¸…æ´—å¯èƒ½çš„ markdown æ ‡è®°
            content = content.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(content)
            
            return CritiqueFeedback(
                passed=data.get("passed", False),
                score=data.get("score", 0),
                suggestion=data.get("suggestion")
            )

        except Exception as e:
            print(f"âš ï¸ [Critic] Validation failed due to API error: {e}")
            # å¦‚æœè§†è§‰æ¨¡å‹æŒ‚äº†ï¼Œä¸ºäº†ä¸é˜»å¡æµç¨‹ï¼Œé»˜è®¤é€šè¿‡ï¼Œä½†æ ‡è®°è­¦å‘Š
            return CritiqueFeedback(passed=True, score=5, suggestion=None)