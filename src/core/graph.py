import asyncio
from langgraph.graph import StateGraph, END, START
from langgraph.constants import Send
from typing import Literal, Dict, Any, List

from src.core.config import settings
from src.core.state import GraphState, AggregateState
from src.core.models import CodeGenerationRequest
from src.components.context_builder import ContextBuilder
from src.components.linter import CodeLinter
from src.components.renderer import ManimRunner
from src.components.critic import VisionCritic 
from src.components.tts import TTSEngine
from src.llm.client import LLMClient
from src.llm.prompts import (
    build_planner_system_prompt, 
    build_planner_user_prompt,
    build_code_user_prompt,
    build_fixer_system_prompt,
    build_fixer_user_prompt
)
from src.utils.code_ops import extract_code
from src.utils.logger import logger, metrics

class ManimGraph:
    """
    å­å›¾ï¼šå¤„ç†å•ä¸ªåœºæ™¯çš„ç”Ÿå‘½å‘¨æœŸ (TTS -> Plan -> Code -> Lint -> Render -> Critic)
    """
    def __init__(self):
        self.context_builder = ContextBuilder()
        
        # ä½¿ç”¨å¼‚æ­¥ LLM Client
        self.planner_llm = LLMClient(model=settings.PLANNER_MODEL)
        self.coder_llm = LLMClient(model=settings.CODER_MODEL)
        
        self.linter = CodeLinter()
        self.runner = ManimRunner()
        self.critic = VisionCritic() 
        self.tts = TTSEngine()
        
        self.MAX_SYNTAX_RETRIES = 3
        self.MAX_VISUAL_RETRIES = 2 

    # --- Node 0: TTS (New in Graph) ---
    async def node_tts(self, state: GraphState) -> Dict[str, Any]:
        """
        å¹¶è¡Œç”ŸæˆéŸ³é¢‘ï¼Œå¹¶ä¿®æ­£ duration
        """
        # [Debug] é˜²å¾¡æ€§æ£€æŸ¥
        if "scene_spec" not in state:
            logger.error(f"âŒ [Node: TTS] Missing 'scene_spec' in state. Keys: {list(state.keys())}")
            raise KeyError("scene_spec")

        scene = state["scene_spec"]
        logger.info(f"ğŸ”Š [Node: TTS] Generating audio for {scene.scene_id}...")
        
        # å°†åŒæ­¥çš„ TTS ç”Ÿæˆæ”¾åˆ°çº¿ç¨‹æ± 
        audio_path = await asyncio.to_thread(
            self.tts.generate, 
            scene.audio_script, 
            scene.scene_id
        )
        
        if audio_path:
            # è·å–æ—¶é•¿
            duration = await asyncio.to_thread(self.tts.get_duration, audio_path)
            if duration > 0:
                scene.duration = round(duration + 0.5, 2)
                logger.info(f"   â±ï¸ [TTS] Updated {scene.scene_id} duration to {scene.duration}s")
        
        # æ›´æ–° state ä¸­çš„ scene_spec (duration å¯èƒ½å˜äº†)
        return {"scene_spec": scene}

    # --- Node 1: Planner ---
    async def node_plan_layout(self, state: GraphState) -> Dict[str, Any]:
        # [Debug] ç¡®ä¿ scene_spec å­˜åœ¨
        if "scene_spec" not in state:
             logger.error("âŒ [Node: Planner] 'scene_spec' missing!")
             raise KeyError("scene_spec")

        logger.info(f"ğŸ¤” [Node: Planner] {state['scene_spec'].scene_id}")
        
        if state.get("layout_plan"):
            return {}

        scene = state["scene_spec"]
        # Async call
        plan = await self.planner_llm.generate_text(
            build_planner_system_prompt(), 
            build_planner_user_prompt(scene)
        )
        
        # Save file (non-blocking ideally, but small file IO is ok)
        try:
            plan_dir = settings.OUTPUT_DIR / "plan"
            plan_dir.mkdir(parents=True, exist_ok=True)
            with open(plan_dir / f"{scene.scene_id}_plan.md", "w", encoding="utf-8") as f:
                f.write(plan)
        except Exception:
            pass

        return {"layout_plan": plan}

    # --- Node 2: Fixer ---
    async def node_analyze_error(self, state: GraphState) -> Dict[str, Any]:
        logger.info(f"ğŸ”§ [Node: Fixer] {state['scene_spec'].scene_id}")
        
        code = state.get("code")
        plan = state.get("layout_plan")
        
        error_context = ""
        if state.get("critic_feedback"):
            error_context = f"VISUAL REPORT:\n{state['critic_feedback']}"
        elif state.get("error_log"):
            error_context = f"TRACEBACK:\n{state['error_log']}"

        sys_prompt = build_fixer_system_prompt(
            self.context_builder.api_stubs, 
            self.context_builder.examples
        )
        user_prompt = build_fixer_user_prompt(plan, code, error_context)
        
        # Async call
        instructions = await self.planner_llm.generate_text(sys_prompt, user_prompt)

        # --- [Add] Save Fix Plan ---
        try:
            scene = state["scene_spec"]
            vis_try = state.get("visual_retries", 0)
            syn_try = state.get("retries", 0)
            
            fix_dir = settings.OUTPUT_DIR / "fix_plan"
            fix_dir.mkdir(parents=True, exist_ok=True)
            
            filename = f"{scene.scene_id}_fix_v{vis_try}_s{syn_try}.md"
            with open(fix_dir / filename, "w", encoding="utf-8") as f:
                f.write(f"# Fix Plan (Runtime_Linter/Visual_Critic)\n\n## Input Error Context\n{error_context}\n\n## Generated Instructions\n{instructions}")
        except Exception as e:
            logger.warning(f"Failed to save fix plan: {e}")

        return {"fix_instructions": instructions}

    # --- Node 3: Coder ---
    async def node_generate_code(self, state: GraphState) -> Dict[str, Any]:
        logger.info(f"ğŸ¤– [Node: Coder] {state['scene_spec'].scene_id}")

        req = CodeGenerationRequest(
            scene=state["scene_spec"],
            previous_code=state.get("code"),
            feedback_context=None 
        )

        plan = state.get("layout_plan", "")
        fix_instructions = state.get("fix_instructions")
        
        error_summary = "No error."
        if state.get("critic_feedback"):
            error_summary = f"Visual: {state['critic_feedback']}"
        elif state.get("error_log"):
            error_summary = f"Runtime: {state['error_log']}"

        sys_prompt = self.context_builder.build_system_prompt()
        user_prompt = build_code_user_prompt(req, plan, fix_instructions, error_summary)
        
        # Async call
        raw_resp = await self.coder_llm.generate_code(sys_prompt, user_prompt)
        new_code = extract_code(raw_resp)

        # --- [Add] Save Generated Code ---
        try:
            scene = state["scene_spec"]
            vis_try = state.get("visual_retries", 0)
            syn_try = state.get("retries", 0)
            
            code_dir = settings.OUTPUT_DIR / "scenes_code"
            code_dir.mkdir(parents=True, exist_ok=True)
            
            filename = f"{scene.scene_id}_code_v{vis_try}_s{syn_try}.py"
            with open(code_dir / filename, "w", encoding="utf-8") as f:
                f.write(new_code)
        except Exception as e:
            logger.warning(f"Failed to save generated code: {e}")

        return {"code": new_code}

    # --- Node 4: Lint (CPU Bound) ---
    async def node_check_syntax(self, state: GraphState) -> Dict[str, Any]:
        # Linter åŒ…å« subprocess è°ƒç”¨ï¼Œè™½ç„¶æ˜¯ CPU å¯†é›†ï¼Œä½†æœ€å¥½ä¹Ÿæ‰”åˆ°çº¿ç¨‹æ± 
        res = await asyncio.to_thread(self.linter.validate, state["code"])
        if res.passed:
            return {"error_log": None}
        else:
            return {"error_log": res.traceback}

    # --- Node 5: Render (Heavy IO/CPU) ---
    async def node_render(self, state: GraphState) -> Dict[str, Any]:
        scene_id = state["scene_spec"].scene_id
        vis_try = state.get("visual_retries", 0)
        # è¿™é‡Œçš„ render_id ä»…ç”¨äºç”Ÿæˆæ–‡ä»¶åï¼Œé¿å…é‡è¯•æ—¶è¦†ç›–æ—§æ–‡ä»¶
        render_id = f"{scene_id}_v{vis_try}" if vis_try > 0 else scene_id

        try:
            # ä½¿ç”¨æ–°çš„ render_async æ–¹æ³• (å¸¦ä¿¡å·é‡)
            artifact = await self.runner.render_async(state["code"], render_id)
            
            # ã€å…³é”®ä¿®å¤ã€‘: 
            # æ— è®º render_id æ˜¯ä»€ä¹ˆï¼ˆä¾‹å¦‚ "scene_01_v1"ï¼‰ï¼Œ
            # è¿™é‡Œçš„ artifact.scene_id å¿…é¡»è¿˜åŸä¸ºåŸå§‹ ID ("scene_01")ã€‚
            # è¿™æ · Assembler æ‰èƒ½æ ¹æ® "scene_01" æ‰¾åˆ° "scene_01.mp3"ã€‚
            if artifact:
                artifact.scene_id = scene_id
            
            return {"artifact": artifact, "error_log": None}
        except Exception as e:
            return {"error_log": str(e), "artifact": None}

    # --- Node 6: Critic (VLM API) ---
    async def node_critic(self, state: GraphState) -> Dict[str, Any]:
        logger.info(f"ğŸ‘€ [Node: Critic] {state['scene_spec'].scene_id}")
        artifact = state.get("artifact")
        
        if not artifact or not artifact.last_frame_path or artifact.last_frame_path == "N/A":
             return {"critic_feedback": None}

        # Critic å†…éƒ¨è°ƒç”¨äº† OpenAI APIï¼Œéœ€è¦çœ‹å®ƒæ˜¯å¦ä¹Ÿæ˜¯ async
        # å‡è®¾ Critic ç›®å‰æ˜¯åŒæ­¥çš„ (requests/standard openai)ï¼Œæˆ‘ä»¬ç”¨ to_thread
        # ç†æƒ³æƒ…å†µæ˜¯æŠŠ Critic ä¹Ÿæ”¹æˆ asyncï¼Œè¿™é‡Œç”¨ to_thread å…¼å®¹
        feedback = await self.critic.review_layout(
            artifact.last_frame_path, 
            state["scene_spec"]
        )
        
        # --- [Add] Save Critic Report ---
        try:
            scene = state["scene_spec"]
            vis_try = state.get("visual_retries", 0)
            
            critic_dir = settings.OUTPUT_DIR / "critic"
            critic_dir.mkdir(parents=True, exist_ok=True)
            
            filename = f"{scene.scene_id}_critic_v{vis_try}.txt"
            content = f"Passed: {feedback.passed}\nScore: {feedback.score}\nEvidence: {feedback.suggestion}"
            
            with open(critic_dir / filename, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            logger.warning(f"Failed to save critic report: {e}")

        visual_evidence = feedback.suggestion if feedback.suggestion else "Visual check failed."

        if feedback.passed:
            return {"critic_feedback": None}
        else:
            return {"critic_feedback": visual_evidence}

    # --- Node 7: Finalizer ---
    async def node_finalize(self, state: GraphState) -> Dict[str, Any]:
        """
        [é‡è¦] å­å›¾ç»“æŸèŠ‚ç‚¹ã€‚
        å°†å•æ•° artifact è½¬æ¢ä¸ºåˆ—è¡¨ output_artifactsï¼Œä»¥ä¾¿çˆ¶å›¾ reducer åˆå¹¶ã€‚
        """
        art = state.get("artifact")
        if art:
            # è®°å½•æˆåŠŸæŒ‡æ ‡
            metrics.log_scene_finish(
                state["scene_spec"].scene_id, True, 
                state.get("retries",0), state.get("visual_retries",0)
            )
            return {"output_artifacts": [art]}
        else:
            # å¤±è´¥è®°å½•
            metrics.log_scene_finish(
                state["scene_spec"].scene_id, False, 0, 0
            )
            return {"output_artifacts": []} # è¿”å›ç©ºåˆ—è¡¨

    # --- Routing ---
    def node_prep_syntax_retry(self, state: GraphState):
        return {"retries": state.get("retries", 0) + 1}

    def node_prep_visual_retry(self, state: GraphState):
        return {
            "visual_retries": state.get("visual_retries", 0) + 1,
            "retries": 0,
            "error_log": None
        }

    def edge_router_after_lint(self, state: GraphState) -> Literal["render", "fixer", "failed"]:
        if state.get("error_log"):
            if state.get("retries", 0) >= self.MAX_SYNTAX_RETRIES:
                return "failed"
            return "fixer" 
        return "render"

    def edge_router_after_render(self, state: GraphState) -> Literal["critic", "finalize", "fixer"]:
        if state.get("error_log"):
            return "fixer"
        if state.get("visual_retries", 0) >= self.MAX_VISUAL_RETRIES:
            return "finalize"
        return "critic"

    def edge_router_after_critic(self, state: GraphState) -> Literal["finalize", "fixer"]:
        if state.get("critic_feedback") is None:
            return "finalize"
        if state.get("visual_retries", 0) >= self.MAX_VISUAL_RETRIES:
            return "finalize"
        return "fixer"

    def edge_router_after_fixer(self, state: GraphState) -> Literal["prep_syn", "prep_vis"]:
        if state.get("critic_feedback"):
            return "prep_vis"
        return "prep_syn"

    def compile(self):
        workflow = StateGraph(GraphState)
        
        workflow.add_node("tts", self.node_tts)
        workflow.add_node("plan", self.node_plan_layout)
        workflow.add_node("generate", self.node_generate_code)
        workflow.add_node("lint", self.node_check_syntax)
        workflow.add_node("render", self.node_render)
        workflow.add_node("critic", self.node_critic)
        workflow.add_node("fixer", self.node_analyze_error)
        workflow.add_node("prep_syn", self.node_prep_syntax_retry)
        workflow.add_node("prep_vis", self.node_prep_visual_retry)
        workflow.add_node("finalize", self.node_finalize)
        workflow.add_node("failed", self.node_finalize) # å¤±è´¥ä¹Ÿèµ° finalizeï¼Œè¿”å›ç©ºåˆ—è¡¨

        # Flow
        workflow.set_entry_point("tts")
        workflow.add_edge("tts", "plan")
        workflow.add_edge("plan", "generate")
        workflow.add_edge("generate", "lint")
        
        workflow.add_conditional_edges("lint", self.edge_router_after_lint, 
                                       {"render": "render", "fixer": "fixer", "failed": "failed"})
        
        workflow.add_conditional_edges("render", self.edge_router_after_render, 
                                       {"critic": "critic", "fixer": "fixer", "finalize": "finalize"})
        
        workflow.add_conditional_edges("critic", self.edge_router_after_critic, 
                                       {"finalize": "finalize", "fixer": "fixer"})
        
        workflow.add_conditional_edges("fixer", self.edge_router_after_fixer, 
                                       {"prep_syn": "prep_syn", "prep_vis": "prep_vis"})
        
        workflow.add_edge("prep_syn", "generate")
        workflow.add_edge("prep_vis", "generate")
        workflow.add_edge("finalize", END)
        workflow.add_edge("failed", END)

        return workflow.compile()

class ParallelManimFlow:
    """
    æ€»æ§å›¾ï¼šè´Ÿè´£ Map (åˆ†å‘åœºæ™¯) å’Œ Reduce (æ”¶é›†ç»“æœ)
    """
    def __init__(self):
        # ç¼–è¯‘å•åœºæ™¯å­å›¾
        self.scene_graph = ManimGraph().compile()

    def map_scenes(self, state: AggregateState):
        """
        Mapper: å°† scenes åˆ—è¡¨è½¬æ¢ä¸ºå¹¶è¡Œçš„ Send ä»»åŠ¡
        """
        # [Debug] æ‰“å° stateï¼Œç¡®è®¤ scenes æ˜¯å¦å­˜åœ¨
        # print(f"DEBUG: Mapping scenes: {len(state.get('scenes', []))}")
        
        tasks = []
        for scene in state["scenes"]:
            # æ„å»ºå®Œæ•´çš„ GraphState åˆå§‹å€¼
            # å¿…é¡»åŒ…å« GraphState æ‰€æœ‰çš„ Required å­—æ®µ
            # Optional å­—æ®µå¯ä»¥è®¾ä¸º None
            initial_scene_state: GraphState = {
                "scene_spec": scene,
                "retries": 0,
                "visual_retries": 0,
                "code": None,
                "error_log": None,
                "critic_feedback": None,
                "layout_plan": None,
                "fix_instructions": None,
                "artifact": None,
                "output_artifacts": []
            }
            tasks.append(Send("process_scene", initial_scene_state))
        return tasks

    def compile(self):
        workflow = StateGraph(AggregateState)

        # æ·»åŠ å¤„ç†èŠ‚ç‚¹çš„å­å›¾
        workflow.add_node("process_scene", self.scene_graph)

        # è®¾ç½®å…¥å£ï¼Œä½¿ç”¨ map_scenes è¿›è¡ŒåŠ¨æ€æ‰‡å‡º
        workflow.add_conditional_edges(START, self.map_scenes)
        
        # æ‰€æœ‰ process_scene å®Œæˆåï¼ŒReducer ä¼šè‡ªåŠ¨å·¥ä½œï¼Œç›´æ¥ç»“æŸ
        workflow.add_edge("process_scene", END)

        return workflow.compile()